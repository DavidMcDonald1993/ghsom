{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import som_functions as som\n",
    "import math\n",
    "import sklearn.metrics as met\n",
    "import sklearn.manifold as man\n",
    "from time import time\n",
    "\n",
    "# ##floyds embedding\n",
    "# def floyd_embedding(G):\n",
    "    \n",
    "#     n = len(G)\n",
    "    \n",
    "#     fl = nx.floyd_warshall(G)\n",
    "    \n",
    "#     #intitialise distance matrix\n",
    "#     D = np.zeros((n, n))\n",
    "    \n",
    "#     #find closest k neighbours\n",
    "#     for i in range(n):\n",
    "#         n1 = G.nodes()[i]\n",
    "#         for j in range(n):\n",
    "#             n2 = G.nodes()[j]\n",
    "#             D[i,j] = fl[n1][n2]\n",
    "            \n",
    "#     return D\n",
    "    \n",
    "def custom_mds(distance_dict):\n",
    "    \n",
    "    #construct distance matrix D from dictionary\n",
    "    D = np.array([[distance_dict[i][j] for j in distance_dict[i]] for i in distance_dict])\n",
    "        \n",
    "    #centering matrix\n",
    "    n = len(distance_dict)\n",
    "    C = np.identity(n) - np.ones((n, n)) / n\n",
    "    #similarity matrix\n",
    "    K = - 1/2 * np.dot(np.dot(C, D ** 2), C)\n",
    "    \n",
    "    #eigen decompose K\n",
    "    l, U = np.linalg.eigh(K)\n",
    "    \n",
    "    ##sort eigenvalues (and eigenvectors) into ascending order\n",
    "    idx = l.argsort()[::-1]\n",
    "    l = l[idx]\n",
    "    U = U[:,idx]\n",
    "    \n",
    "    s = sum(l)\n",
    "    \n",
    "    k = len(l)\n",
    "    var = 1\n",
    "    \n",
    "    while var > 0.95:\n",
    "        k -= 1\n",
    "        var = sum(l[:k]) / s\n",
    "    \n",
    "    k += 1\n",
    "    \n",
    "    #position matrix\n",
    "    X = np.dot(U[:,:k], np.diag(l[:k] ** 0.5))\n",
    "    \n",
    "    #link nodes to embedding\n",
    "    X = {k: v for k, v in zip(distance_dict, X)}\n",
    "    \n",
    "    return X\n",
    "\n",
    "##function to generate benchmark graph\n",
    "def benchmark_hierarchical_graph(edge_path, c1_path, c2_path):\n",
    "\n",
    "    #construct graph from edge list\n",
    "    G = nx.read_edgelist(edge_path)\n",
    "\n",
    "    #create dictionarys of attributes\n",
    "    c1 = read_attributes(c1_path)\n",
    "    c2 = read_attributes(c2_path)\n",
    "\n",
    "    #set attributes of G\n",
    "    nx.set_node_attributes(G, 'firstlevelcommunity', c1)\n",
    "    nx.set_node_attributes(G, 'secondlevelcommunity', c2)\n",
    "    \n",
    "    #return graph\n",
    "    return G\n",
    "\n",
    "##function to generate benchmark graph\n",
    "def benchmark_graph(edge_path, c_path):\n",
    "    \n",
    "    #construct graph from edge list\n",
    "    G = nx.read_edgelist(edge_path)\n",
    "\n",
    "    #create dictionarys of attributes\n",
    "    c = read_attributes(c_path)\n",
    "\n",
    "    #set attributes of G\n",
    "    nx.set_node_attributes(G, 'firstlevelcommunity', c)\n",
    "    \n",
    "    #return graph\n",
    "    return G\n",
    "\n",
    "##function to read in attributes from file and return a dictionary\n",
    "def read_attributes(filepath):\n",
    "    \n",
    "    #initialise dictionary\n",
    "    d = {}\n",
    "    \n",
    "    #open file\n",
    "    with open(filepath) as f:\n",
    "        \n",
    "        #iterate over lines in f\n",
    "        for l in f:\n",
    "            \n",
    "            #separate into key and value\n",
    "            k, v = l.split()\n",
    "            \n",
    "            #add to dictionary\n",
    "            d[k] = v\n",
    "    \n",
    "    #return\n",
    "    return d\n",
    "\n",
    "def filter_nodes_with_no_embedding(G, D):\n",
    "    \n",
    "    for n in G.nodes():\n",
    "    \n",
    "        if n not in D:\n",
    "            print \"{} not in D, removing it from the network\".format(n)\n",
    "            G.remove_node(n)\n",
    "\n",
    "##save embedding to graph\n",
    "def set_embedding(G, X):\n",
    "    \n",
    "    #get number of niodes in the graph\n",
    "#     num_nodes = nx.number_of_nodes(G)\n",
    "    \n",
    "    #dimension of embedding\n",
    "    d = len(X[G.nodes()[0]])\n",
    "    \n",
    "    #iterate over a;; the nodes and save their embedding\n",
    "    for n in G.nodes():\n",
    "        for j in range(d):\n",
    "            G.node[n]['embedding{}'.format(j)] = X[n][j]    \n",
    "\n",
    "def main_hierarchical(network, first_level, second_level):\n",
    "    \n",
    "    #import graph from file\n",
    "    G = benchmark_hierarchical_graph(network, first_level, second_level)\n",
    "    \n",
    "    #only embed largest subgraph\n",
    "    H = max(nx.connected_component_subgraphs(G), key=len)\n",
    "    \n",
    "    #embed into X\n",
    "    D = nx.floyd_warshall(H)\n",
    "    \n",
    "    #remove nodes from H with no embedding\n",
    "    filter_nodes_with_no_embedding(H, D)    \n",
    "    \n",
    "    #mds\n",
    "    X = custom_mds(D) \n",
    "    \n",
    "    #save embedding to nodes of G\n",
    "    set_embedding(H, X)\n",
    "    \n",
    "    #write gml file\n",
    "    nx.write_gml(H, 'embedded_network_{}.gml'.format(network.split('_')[0]))\n",
    "\n",
    "def main_binary(network, first_level, gml_filename):\n",
    "    \n",
    "    #import graph from file\n",
    "    G = benchmark_graph(network, first_level)\n",
    "    \n",
    "    #only embed largest subgraph\n",
    "    H = max(nx.connected_component_subgraphs(G), key=len)\n",
    "    \n",
    "    #embed into X\n",
    "    D = nx.floyd_warshall(H)\n",
    "    \n",
    "    #remove nodes from H with no embedding\n",
    "    filter_nodes_with_no_embedding(H, D)    \n",
    "    \n",
    "    #mds\n",
    "    X = custom_mds(D) \n",
    "    \n",
    "    #save embedding to nodes of G\n",
    "    set_embedding(H, X)\n",
    "    \n",
    "    #write gml file\n",
    "    nx.write_gml(H, gml_filename)\n",
    "\n",
    "def main(txt, gml_filename, D=None):\n",
    "    \n",
    "    #import graph from file\n",
    "    G = nx.read_edgelist(txt)\n",
    "    \n",
    "    #only embed largest subgraph\n",
    "    H = max(nx.connected_component_subgraphs(G), key=len)\n",
    "    \n",
    "    #embed into X\n",
    "    if D == None:\n",
    "        #if no precomuped distance matrix then use floyd\n",
    "        D = nx.floyd_warshall(H)\n",
    "    \n",
    "    #remove nodes from H with no embedding\n",
    "    filter_nodes_with_no_embedding(H, D)    \n",
    "    \n",
    "    #mds\n",
    "    X = custom_mds(D)   \n",
    "    \n",
    "    #save embedding to nodes of G\n",
    "    set_embedding(H, X)\n",
    "    \n",
    "    #write gml file\n",
    "    nx.write_gml(H, gml_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_binary(\"benchmarks/network.dat\", \"benchmarks/community.dat\", \"benchmarks/embedded_benchmark_3.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YNL054WB not in D, removing it from the network\n",
      "YAL046C not in D, removing it from the network\n",
      "YFR024CA not in D, removing it from the network\n",
      "YLR294C not in D, removing it from the network\n",
      "YBR190W not in D, removing it from the network\n",
      "YBR176W not in D, removing it from the network\n",
      "YBR134W not in D, removing it from the network\n",
      "YGL214W not in D, removing it from the network\n",
      "YER087CA not in D, removing it from the network\n",
      "YCL020W not in D, removing it from the network\n",
      "YNL198C not in D, removing it from the network\n",
      "YFL002WA not in D, removing it from the network\n",
      "YDR203W not in D, removing it from the network\n",
      "YDR261WA not in D, removing it from the network\n",
      "YDR261WB not in D, removing it from the network\n",
      "TORF21 not in D, removing it from the network\n",
      "YKL003WA not in D, removing it from the network\n",
      "YKL076C not in D, removing it from the network\n",
      "YIL104C not in D, removing it from the network\n",
      "YDL071C not in D, removing it from the network\n",
      "YCR020CA not in D, removing it from the network\n",
      "YCL046W not in D, removing it from the network\n",
      "YMR204C not in D, removing it from the network\n",
      "YCR087CA not in D, removing it from the network\n",
      "YMR124W not in D, removing it from the network\n",
      "TORF1 not in D, removing it from the network\n",
      "YDR431W not in D, removing it from the network\n",
      "YLR465C not in D, removing it from the network\n",
      "YBR040W not in D, removing it from the network\n",
      "YDR063W not in D, removing it from the network\n",
      "YIL082W not in D, removing it from the network\n",
      "YER188W not in D, removing it from the network\n",
      "YLR112W not in D, removing it from the network\n",
      "YLR279W not in D, removing it from the network\n",
      "YMR316CB not in D, removing it from the network\n",
      "YGR173W not in D, removing it from the network\n",
      "YLR322W not in D, removing it from the network\n",
      "YBL101WA not in D, removing it from the network\n",
      "YOR379C not in D, removing it from the network\n",
      "YBR162WA not in D, removing it from the network\n",
      "YOR331C not in D, removing it from the network\n",
      "YJL086C not in D, removing it from the network\n",
      "YAL044WA not in D, removing it from the network\n",
      "YMR294WA not in D, removing it from the network\n",
      "YDR008C not in D, removing it from the network\n",
      "YMR163C not in D, removing it from the network\n",
      "YLR120WA not in D, removing it from the network\n",
      "YBL091CA not in D, removing it from the network\n",
      "YGL024W not in D, removing it from the network\n",
      "YPR126C not in D, removing it from the network\n",
      "YIL105WA not in D, removing it from the network\n",
      "YHR180W not in D, removing it from the network\n",
      "YJL211C not in D, removing it from the network\n",
      "YNL279W not in D, removing it from the network\n",
      "YCL021WA not in D, removing it from the network\n",
      "YOL109W not in D, removing it from the network\n",
      "YER096W not in D, removing it from the network\n",
      "YJR023C not in D, removing it from the network\n",
      "YGR136W not in D, removing it from the network\n",
      "YPL049C not in D, removing it from the network\n",
      "YIR003W not in D, removing it from the network\n",
      "YOR318C not in D, removing it from the network\n",
      "YJR010CA not in D, removing it from the network\n",
      "YDR229W not in D, removing it from the network\n",
      "YLR438CA not in D, removing it from the network\n",
      "YCL063W not in D, removing it from the network\n",
      "YJL127WA not in D, removing it from the network\n",
      "YOL050C not in D, removing it from the network\n",
      "YPL255W not in D, removing it from the network\n",
      "YGL220W not in D, removing it from the network\n",
      "YGR286C not in D, removing it from the network\n",
      "MEL1 not in D, removing it from the network\n",
      "YDR320CA not in D, removing it from the network\n",
      "YPL176C not in D, removing it from the network\n",
      "YAL036C not in D, removing it from the network\n",
      "YAL034WA not in D, removing it from the network\n",
      "YFL061W not in D, removing it from the network\n",
      "YPR159CA not in D, removing it from the network\n",
      "YDR152W not in D, removing it from the network\n",
      "YJL064W not in D, removing it from the network\n",
      "YFL034CB not in D, removing it from the network\n",
      "YDL133CA not in D, removing it from the network\n",
      "YJL135W not in D, removing it from the network\n",
      "TORF47 not in D, removing it from the network\n",
      "YNR025C not in D, removing it from the network\n",
      "YOR192CA not in D, removing it from the network\n",
      "YOR262W not in D, removing it from the network\n",
      "YNL204C not in D, removing it from the network\n",
      "YNL042W not in D, removing it from the network\n",
      "YHR185C not in D, removing it from the network\n",
      "YJL077WB not in D, removing it from the network\n",
      "YER007CA not in D, removing it from the network\n",
      "YBR270C not in D, removing it from the network\n",
      "YMR316W not in D, removing it from the network\n",
      "YOL106W not in D, removing it from the network\n",
      "YDR480W not in D, removing it from the network\n",
      "YDR455C not in D, removing it from the network\n",
      "YJL075C not in D, removing it from the network\n",
      "YOR304CA not in D, removing it from the network\n",
      "YDL118W not in D, removing it from the network\n",
      "YBR137W not in D, removing it from the network\n",
      "YIR044C not in D, removing it from the network\n",
      "YLR333C not in D, removing it from the network\n",
      "YDR526C not in D, removing it from the network\n",
      "YPL251W not in D, removing it from the network\n",
      "YDL011C not in D, removing it from the network\n",
      "YKR100C not in D, removing it from the network\n",
      "YDR271C not in D, removing it from the network\n",
      "YNL171C not in D, removing it from the network\n",
      "YBR126WA not in D, removing it from the network\n",
      "YPR136C not in D, removing it from the network\n",
      "TORF19 not in D, removing it from the network\n",
      "YGL170C not in D, removing it from the network\n",
      "YGR027C not in D, removing it from the network\n",
      "YER056CA not in D, removing it from the network\n",
      "YGR269W not in D, removing it from the network\n",
      "YFL017WA not in D, removing it from the network\n",
      "YHR072WA not in D, removing it from the network\n"
     ]
    }
   ],
   "source": [
    "graph_file = \"Y2H_union.txt\"\n",
    "gml_filename = \"embedded_yeast_union_rel.gml\"\n",
    "distance_file = \"yeast_union_rel_similarity_GOSim.csv\"\n",
    "\n",
    "labels = np.genfromtxt(distance_file, delimiter=',', usecols=0, dtype=str)\n",
    "raw_data = np.genfromtxt(distance_file, delimiter=',')[:,1:]\n",
    "D = {label.replace(\"\\\"\", \"\") : \n",
    "     {label.replace(\"\\\"\", \"\") : element for label, element in zip(labels, row)} \n",
    "     for label, row in zip(labels, raw_data)}\n",
    "\n",
    "main(graph_file, gml_filename, D=D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p=0.9\n",
      "yeast_union_rel_communities_0.9_1.pkl already exists, loading map\n",
      "moved to yeast_union_rel_communities_0.9_1\n",
      "written all_genes.txt\n",
      "written shortest path matrix\n",
      "written community_0.txt\n",
      "written community_1.txt\n",
      "\n",
      "p=0.8\n",
      "yeast_union_rel_communities_0.8_1.pkl already exists, loading map\n",
      "moved to yeast_union_rel_communities_0.8_1\n",
      "written all_genes.txt\n",
      "written shortest path matrix\n",
      "written community_0.txt\n",
      "written community_1.txt\n",
      "written community_2.txt\n",
      "\n",
      "p=0.7\n",
      "running GHSOM and saving to yeast_union_rel_communities_0.7_1.pkl\n",
      "Layer: 1, training epoch: 999/1000, size of map: 4, MQE: 0.501463387018, target: 0.483993589392, sigma: 0.135606224654          \n",
      "number of communities detected: 4, saved map to yeast_union_rel_communities_0.7_1\n",
      "made directory yeast_union_rel_communities_0.7_1\n",
      "moved to yeast_union_rel_communities_0.7_1\n",
      "written all_genes.txt\n",
      "written shortest path matrix\n",
      "written community_0.txt\n",
      "written community_1.txt\n",
      "written community_2.txt\n",
      "written community_3.txt\n",
      "\n",
      "p=0.6\n",
      "running GHSOM and saving to yeast_union_rel_communities_0.6_1.pkl\n",
      "Layer: 1, training epoch: 999/1000, size of map: 7, MQE: 0.41967357061, target: 0.415402463919, sigma: 0.135606224654           \n",
      "number of communities detected: 7, saved map to yeast_union_rel_communities_0.6_1\n",
      "made directory yeast_union_rel_communities_0.6_1\n",
      "moved to yeast_union_rel_communities_0.6_1\n",
      "written all_genes.txt\n",
      "written shortest path matrix\n",
      "written community_0.txt\n",
      "written community_1.txt\n",
      "written community_2.txt\n",
      "written community_3.txt\n",
      "written community_4.txt\n",
      "written community_5.txt\n",
      "written community_6.txt\n",
      "\n",
      "p=0.5\n",
      "running GHSOM and saving to yeast_union_rel_communities_0.5_1.pkl\n",
      "Layer: 1, training epoch: 999/1000, size of map: 12, MQE: 0.349144059791, target: 0.345651674802, sigma: 0.135606224654          \n",
      "number of communities detected: 12, saved map to yeast_union_rel_communities_0.5_1\n",
      "made directory yeast_union_rel_communities_0.5_1\n",
      "moved to yeast_union_rel_communities_0.5_1\n",
      "written all_genes.txt\n",
      "written shortest path matrix\n",
      "written community_0.txt\n",
      "written community_1.txt\n",
      "written community_2.txt\n",
      "written community_3.txt\n",
      "written community_4.txt\n",
      "written community_5.txt\n",
      "written community_6.txt\n",
      "written community_7.txt\n",
      "written community_8.txt\n",
      "written community_9.txt\n",
      "written community_10.txt\n",
      "written community_11.txt\n",
      "\n",
      "p=0.4\n",
      "running GHSOM and saving to yeast_union_rel_communities_0.4_1.pkl\n",
      "Layer: 1, training epoch: 999/1000, size of map: 26, MQE: 0.283554894993, target: 0.277034124082, sigma: 0.135606224654          \n",
      "number of communities detected: 26, saved map to yeast_union_rel_communities_0.4_1\n",
      "made directory yeast_union_rel_communities_0.4_1\n",
      "moved to yeast_union_rel_communities_0.4_1\n",
      "written all_genes.txt\n",
      "written shortest path matrix\n",
      "written community_0.txt\n",
      "written community_1.txt\n",
      "written community_2.txt\n",
      "written community_3.txt\n",
      "written community_4.txt\n",
      "written community_5.txt\n",
      "written community_6.txt\n",
      "written community_7.txt\n",
      "written community_8.txt\n",
      "written community_9.txt\n",
      "written community_10.txt\n",
      "written community_11.txt\n",
      "written community_12.txt\n",
      "written community_13.txt\n",
      "written community_14.txt\n",
      "written community_15.txt\n",
      "written community_16.txt\n",
      "written community_17.txt\n",
      "written community_18.txt\n",
      "written community_19.txt\n",
      "written community_20.txt\n",
      "written community_21.txt\n",
      "written community_22.txt\n",
      "written community_23.txt\n",
      "written community_24.txt\n",
      "written community_25.txt\n",
      "\n",
      "p=0.3\n",
      "running GHSOM and saving to yeast_union_rel_communities_0.3_1.pkl\n",
      "Layer: 1, training epoch: 999/1000, size of map: 35, MQE: 0.254475584931, target: 0.207440728055, sigma: 0.135606224654          deleted node 14\n",
      "Layer: 1, training epoch: 995/1000, size of map: 37, MQE: 0.253101740016, target: 0.207440728055, sigma: 0.136695425446          "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fbe0255c9e3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#run ghsom and save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"running GHSOM and saving to {}.pkl\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mghsom_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embedded_{}.gml'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\nnumber of communities detected: {}, saved map to {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0msave_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/Documents/ghsom/ghsom.py\u001b[0m in \u001b[0;36mmain_no_labels\u001b[0;34m(params, gml_filename, init, lam)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0;31m#run ghsom algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     network, MQE = ghsom(G, lam, params['w'], params['eta'],\n\u001b[0;32m--> 851\u001b[0;31m                          params['sigma'], np.inf, params['e_sg'], params['e_en'], init, layer)\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/Documents/ghsom/ghsom.py\u001b[0m in \u001b[0;36mghsom\u001b[0;34m(G, lam, w, eta, sigma, e_0, e_sg, e_en, init, layer)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;31m#recursively run algorithm to create new network for subgraph of this neurons nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mghsom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_sg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;31m#repack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/Documents/ghsom/ghsom.py\u001b[0m in \u001b[0;36mghsom\u001b[0;34m(G, lam, w, eta, sigma, e_0, e_sg, e_en, init, layer)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;31m#train for l epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMQE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_sg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0me_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;31m#classify nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/Documents/ghsom/ghsom.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(X, network, num_epochs, eta_0, sigma_0, N, layer, MQE, target)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m#determine winning neuron\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mwin_neuron\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwinning_neuron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/Documents/ghsom/ghsom.py\u001b[0m in \u001b[0;36mwinning_neuron\u001b[0;34m(x, network)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m#distance between input vector and neuron weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# if we have a new closest neuron\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2164\u001b[0m     \u001b[0;31m# Immediately handle some default, simple, fast, and common cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2166\u001b[0;31m         \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2167\u001b[0m         if ((ord is None) or\n\u001b[1;32m   2168\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fro'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from ghsom import main_no_labels as ghsom_main\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "root_dir = \"/home/david/Documents/ghsom\"\n",
    "\n",
    "data = \"yeast_union_rel\"\n",
    "init = 1\n",
    "\n",
    "for p in np.arange(0.1, 1, 0.1)[::-1]:\n",
    "    \n",
    "    print \"p={}\".format(p)\n",
    "    \n",
    "    os.chdir(root_dir)\n",
    "    \n",
    "    #ghsom parameters\n",
    "    params = {'w': 0.0001,\n",
    "             'eta': 0.001,\n",
    "             'sigma': 1,\n",
    "              'e_sg': p,\n",
    "             'e_en': 10}\n",
    "    \n",
    "    map_file = '{}_communities_{}_{}'.format(data, p, init)\n",
    "    \n",
    "    if not os.path.isfile(\"{}.pkl\".format(map_file)):\n",
    "    \n",
    "        #run ghsom and save output\n",
    "        print \"running GHSOM and saving to {}.pkl\".format(map_file)\n",
    "        G, map = ghsom_main(params, 'embedded_{}.gml'.format(data), init=init, lam=1000)\n",
    "        print '\\nnumber of communities detected: {}, saved map to {}'.format(len(map), map_file)\n",
    "        save_obj((G, map), map_file)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print \"{}.pkl already exists, loading map\".format(map_file)    \n",
    "        #load output\n",
    "        G, map = load_obj(map_file)\n",
    "\n",
    "    #save results to file\n",
    "    dir_name = \"{}_communities_{}_{}\".format(data, p, init)\n",
    "    if not os.path.isdir(dir_name):\n",
    "#         shutil.rmtree(dir_name)\n",
    "#         print \"deleted directory {}\".format(dir_name)\n",
    "    \n",
    "        os.mkdir(dir_name)\n",
    "        print 'made directory {}'.format(dir_name)\n",
    "\n",
    "    os.chdir(dir_name)\n",
    "    print \"moved to {}\".format(dir_name)\n",
    "    \n",
    "    #all genes\n",
    "    all_genes_file = \"all_genes.txt\"\n",
    "    with open(all_genes_file, 'w') as f:\n",
    "        for n in G.nodes():\n",
    "            f.write(\"{}\\n\".format(n))\n",
    "    print \"written {}\".format(all_genes_file)\n",
    "    \n",
    "    #save shortest path matrix\n",
    "    shortest_path = nx.floyd_warshall_numpy(map).astype(np.int)\n",
    "    np.savetxt(\"shortest_path.csv\", shortest_path, fmt='%i', delimiter=\",\")\n",
    "    print 'written shortest path matrix'\n",
    "    \n",
    "    #save communities to file\n",
    "    c = 0\n",
    "    for n, d in map.nodes(data=True):\n",
    "        ls = d['ls']\n",
    "        with open('community_{}.txt'.format(c),'w') as f:\n",
    "            for l in ls:\n",
    "                f.write('{}\\n'.format(l))\n",
    "        print 'written community_{}.txt'.format(c)\n",
    "        c += 1\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already completed 5/1, loading scores and continuing\n",
      "already completed 5/0.9, loading scores and continuing\n",
      "already completed 5/0.8, loading scores and continuing\n",
      "already completed 5/0.7, loading scores and continuing\n",
      "already completed 5/0.6, loading scores and continuing\n",
      "already completed 5/0.5, loading scores and continuing\n",
      "already completed 10/1, loading scores and continuing\n",
      "already completed 10/0.9, loading scores and continuing\n",
      "already completed 10/0.8, loading scores and continuing\n",
      "already completed 10/0.7, loading scores and continuing\n",
      "already completed 10/0.6, loading scores and continuing\n",
      "already completed 10/0.5, loading scores and continuing\n",
      "already completed 20/1, loading scores and continuing\n",
      "already completed 20/0.9, loading scores and continuing\n",
      "already completed 20/0.8, loading scores and continuing\n",
      "already completed 20/0.7, loading scores and continuing\n",
      "already completed 20/0.6, loading scores and continuing\n",
      "already completed 20/0.5, loading scores and continuing\n",
      "DONE\n",
      "OVERALL NMI SCORES\n",
      "[[ 0.27476587  0.83336704  0.90450324  0.91449138  0.94343971  0.96281918]\n",
      " [ 0.14636193  0.75272783  0.93184494  0.93900269  0.97446963  0.97871165]\n",
      " [ 0.13327068  0.61287572  0.83201858  0.9075935   0.94019638  0.96549768]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "import subprocess\n",
    "from save_embedded_graph27 import main_binary as embed_main\n",
    "from spearmint_ghsom import main as ghsom_main\n",
    "import numpy as np\n",
    "import pickle\n",
    "from time import time\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "#root dir\n",
    "os.chdir(\"C:\\Miniconda3\\Jupyter\\GHSOM_simplex_dsd\")\n",
    "\n",
    "#save directory\n",
    "dir = os.path.abspath(\"parameter_tests_2\")\n",
    "\n",
    "#number of times to repeat\n",
    "num_repeats = 30\n",
    "\n",
    "#number of nodes in communitiy\n",
    "s1 = 32\n",
    "\n",
    "#number of links to same community\n",
    "z1 = 16\n",
    "\n",
    "#number of nodes in micro community\n",
    "minc = s1\n",
    "maxc = s1\n",
    "\n",
    "#make save directory\n",
    "if not os.path.isdir(dir):\n",
    "    os.mkdir(dir)\n",
    "\n",
    "#change to dir\n",
    "os.chdir(dir)    \n",
    "\n",
    "#network file names -- output of network generator\n",
    "network = \"network.dat\"\n",
    "first_level = \"community.dat\"\n",
    "\n",
    "#community labels\n",
    "labels = 'firstlevelcommunity'\n",
    "\n",
    "#mixing parameter\n",
    "z2 = 16\n",
    "\n",
    "#node degree\n",
    "k = z1 + z2\n",
    "maxk = k\n",
    "\n",
    "#mixing factors\n",
    "mu = float(z2) / k \n",
    "\n",
    "num_communities = [5, 10, 20]\n",
    "parameter_settings = [0.5, 0.6, 0.7, 0.8, 0.9, 1][::-1]\n",
    "\n",
    "overall_nmi_scores = np.zeros((len(num_communities), len(parameter_settings)))\n",
    "\n",
    "for i in range(len(num_communities)):\n",
    "# for k1 in num_communities:\n",
    "    k1 = num_communities[i]\n",
    "    \n",
    "    #number of nodes in the network\n",
    "    N = k1 * s1\n",
    "    \n",
    "    #create directory\n",
    "    dir_string = os.path.join(dir, str(k1))\n",
    "    if not os.path.isdir(dir_string):\n",
    "        os.mkdir(dir_string)\n",
    "    \n",
    "    #change working directory    \n",
    "    os.chdir(dir_string)\n",
    "    \n",
    "    for j in range(len(parameter_settings)):\n",
    "#     for p in parameter_settings:\n",
    "        \n",
    "        p = parameter_settings[j]\n",
    "        \n",
    "        #ghsom parameters\n",
    "        params = {'w': 0.0001,\n",
    "                 'eta': 0.0001,\n",
    "                 'sigma': 1,\n",
    "                  'e_sg': p,\n",
    "                 'e_en': 0.8}\n",
    "    \n",
    "        #create directory\n",
    "        dir_string_p = os.path.join(dir_string, str(p))\n",
    "        if not os.path.isdir(dir_string_p):\n",
    "            os.mkdir(dir_string_p)\n",
    "    \n",
    "        #change working directory    \n",
    "        os.chdir(dir_string_p)\n",
    "        \n",
    "        if os.path.isfile('nmi_scores.csv'):\n",
    "            print 'already completed {}/{}, loading scores and continuing'.format(k1, p)\n",
    "            nmi_scores = np.genfromtxt('nmi_scores.csv', delimiter=',')\n",
    "            overall_nmi_scores[i,j] = np.mean(nmi_scores, axis=0)\n",
    "            continue\n",
    "        \n",
    "        #copy executable\n",
    "        ex = \"benchmark.exe\"   \n",
    "        if not os.path.isfile(ex):\n",
    "\n",
    "            source = \"C:\\\\Users\\\\davem\\\\Documents\\\\PhD\\\\Benchmark Graph Generators\\\\binary_networks\\\\benchmark.exe\"\n",
    "            copyfile(source, ex)\n",
    "\n",
    "        #make benchmark parameter file\n",
    "        filename = \"benchmark_flags_{}_{}.dat\".format(k1,p)\n",
    "        if not os.path.isfile(filename):\n",
    "            with open(filename,\"w\") as f:\n",
    "                f.write(\"-N {} -k {} -maxk {} -minc {} -maxc {} -mu {}\".format(N, k, maxk, minc, maxc, mu))\n",
    "            print 'written flag file: {}'.format(filename)\n",
    "            \n",
    "        #cmd strings\n",
    "        change_dir_cmd = \"cd {}\".format(dir_string_p)\n",
    "        generate_network_cmd = \"benchmark -f {}\".format(filename)\n",
    "\n",
    "        #output of cmd\n",
    "        output_file = open(\"cmd_output.out\", 'w')\n",
    "\n",
    "        #record NMI scores\n",
    "        if not os.path.isfile('nmi_scores.pkl'):\n",
    "            print 'creating new nmi scores array'\n",
    "            nmi_scores = np.zeros(num_repeats)\n",
    "        else:\n",
    "            print 'loading nmi score progress'\n",
    "            nmi_scores = load_obj('nmi_scores')\n",
    "\n",
    "        #record running times\n",
    "        if not os.path.isfile('running_times.pkl'):\n",
    "            print 'creating new running time array'\n",
    "            running_times = np.zeros(num_repeats)\n",
    "        else:\n",
    "            print 'loading running time progress'\n",
    "            running_times = load_obj('running_times')\n",
    "            \n",
    "        print\n",
    "\n",
    "        #generate networks\n",
    "        for r in range(1, num_repeats+1):\n",
    "\n",
    "            network_rename = \"{}_{}\".format(r,network)\n",
    "            first_level_rename = \"{}_{}\".format(r,first_level)\n",
    "            gml_filename = 'embedded_network_{}.gml'.format(r)\n",
    "\n",
    "            if not os.path.isfile(network_rename):\n",
    "\n",
    "                process = subprocess.Popen(change_dir_cmd + \" && \" + generate_network_cmd, \n",
    "                                        stdout=output_file, \n",
    "                                        stderr=output_file, \n",
    "                                        shell=True)\n",
    "                process.wait()\n",
    "                \n",
    "                print 'generated graph {}'.format(r)\n",
    "\n",
    "                os.rename(network, network_rename)\n",
    "                os.rename(first_level, first_level_rename)\n",
    "                \n",
    "                print 'renamed graph {}'.format(r)\n",
    "\n",
    "            if not os.path.isfile(gml_filename):\n",
    "\n",
    "                ##embed graph\n",
    "                embed_main(network_rename, first_level_rename)\n",
    "\n",
    "                print 'embedded graph {} as {} in {}'.format(r, gml_filename, os.getcwd())\n",
    "\n",
    "            ##score for this network\n",
    "            if not np.all(nmi_scores[r-1]):\n",
    "\n",
    "                start_time = time()\n",
    "\n",
    "                print 'starting ghsom for: {}/{}/{}'.format(k1, p, gml_filename)\n",
    "                nmi_score, communities_detected = ghsom_main(params, gml_filename, labels)\n",
    "                nmi_scores[r-1] = nmi_score\n",
    "\n",
    "                running_time = time() - start_time\n",
    "                print 'running time of algorithm: {}'.format(running_time)\n",
    "                running_times[r-1] = running_time\n",
    "\n",
    "                #save\n",
    "                save_obj(nmi_scores, 'nmi_scores')\n",
    "                save_obj(running_times, 'running_times')\n",
    "\n",
    "                print 'saved nmi score for network {}: {}'.format(gml_filename, nmi_score)\n",
    "                print\n",
    "\n",
    "        ##output nmi scores to csv file\n",
    "        print 'writing nmi scores and running times to file'\n",
    "        np.savetxt('nmi_scores.csv',nmi_scores,delimiter=',')\n",
    "        np.savetxt('running_times.csv',running_times,delimiter=',')\n",
    "        print\n",
    "    \n",
    "print 'DONE'\n",
    "\n",
    "print 'OVERALL NMI SCORES'\n",
    "print overall_nmi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.35632148  0.33486922  0.35229303  0.22688871  0.11498475]\n",
      "0.2\n",
      "[ 0.66275255  0.60090522  0.50301436  0.49588778  0.09876066]\n",
      "0.2\n",
      "[ 0.75081969  0.73525978  0.71798402  0.51541049  0.36483149]\n",
      "0.2\n",
      "[ 0.74710549  0.73859407  0.62326257  0.46137132  0.27593319]\n",
      "0.2\n",
      "[ 0.78002338  0.70857     0.65989855  0.53043045  0.33119491]\n",
      "0.2\n",
      "[ 0.77031049  0.73689024  0.67103124  0.50923749  0.04067397]\n",
      "0.2\n",
      "[ 0.78066878  0.71794796  0.68473928  0.51168871  0.17288067]\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "for scores in overall_nmi_scores:\n",
    "    \n",
    "    print scores\n",
    "    idx = np.argsort(scores)[::-1]\n",
    "    \n",
    "    print parameter_settings[idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from sys import stdout\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sklearn.metrics as met\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import repeat\n",
    "\n",
    "from Queue import Queue\n",
    "from threading import Thread\n",
    "from threading import current_thread\n",
    "\n",
    "MIN_EXPANSION_SIZE = 50\n",
    "MAX_DELETED_NEURONS = 3\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "##function to visualise graph\n",
    "def visualise_graph(G, colours, layer):\n",
    "        \n",
    "    ## create new figure for graph plot\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # graph layout\n",
    "    pos = nx.spring_layout(G)\n",
    "    \n",
    "    #attributes in this graph\n",
    "    attributes = np.unique([v for k, v in nx.get_node_attributes(G, \"assigned_community_layer_{}\".format(layer)).items()])\n",
    "\n",
    "    # draw nodes -- colouring by cluster\n",
    "    for i in range(min(len(colours), len(attributes))):\n",
    "       \n",
    "        node_list = [n for n in G.nodes() if G.node[n][\"assigned_community_layer_{}\".format(layer)] == attributes[i]]\n",
    "        colour = [colours[i] for n in range(len(node_list))]\n",
    "        \n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=node_list, node_color=colour)\n",
    "        \n",
    "    #draw edges\n",
    "    nx.draw_networkx_edges(G, pos)\n",
    "\n",
    "    # draw labels\n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "    \n",
    "    #title of plot\n",
    "    plt.title('Nodes coloured by cluster, layer: {}'.format(layer))\n",
    "\n",
    "    #show plot\n",
    "    plt.show()\n",
    "\n",
    "## visualise graph based on network clusters\n",
    "def visualise_network(network, colours, layer):\n",
    "    \n",
    "    #num neurons in lattice\n",
    "    num_neurons = len(network)\n",
    "\n",
    "    ##create new figure for lattice plot\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # graph layout\n",
    "    pos = nx.spring_layout(network)\n",
    "\n",
    "    # draw nodes -- colouring by cluster\n",
    "    for i in range(len(colours)):\n",
    "        nx.draw_networkx_nodes(network, pos, nodelist = [network.nodes()[i]], node_color = colours[i])\n",
    "\n",
    "    #draw edges\n",
    "    nx.draw_networkx_edges(network, pos)\n",
    "\n",
    "    # draw labels\n",
    "    nx.draw_networkx_labels(network, pos)\n",
    "    \n",
    "    #label axes\n",
    "    plt.title('Neurons in lattice, layer: '+str(layer))\n",
    "    \n",
    "    #show lattice plot\n",
    "    plt.show()\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "def initialise_weight(G):\n",
    "    \n",
    "    print \"INITIALISE WEIGHT, NUMBER OF NODES: {}, CONNECTED: {}\".format(len(G), nx.is_connected(G))\n",
    "    \n",
    "    n = G.nodes()[np.random.randint(len(G))]\n",
    "    \n",
    "    neighbours = G.neighbors(n)\n",
    "    \n",
    "    m = neighbours[np.random.randint(len(neighbours))]\n",
    "    \n",
    "    return n, m, np.random.rand()\n",
    "\n",
    "#function to generate real valued som for graph input\n",
    "#three initial nodes\n",
    "def initialise_network(ID, G, starting_nodes=3):\n",
    "    \n",
    "    #network will be a one dimensional list\n",
    "    network = nx.Graph(ID = ID)\n",
    "    \n",
    "    #initialise a network with just one neuron\n",
    "    network.add_nodes_from(range(1, starting_nodes + 1))\n",
    "    \n",
    "    #id of nodes\n",
    "    for n in network.nodes():\n",
    "        network.node[n][\"ID\"] = \"{}-{}\".format(ID, str(n).zfill(2))\n",
    "        \n",
    "    #connect nodes     \n",
    "    for i in range(1, starting_nodes + 1):\n",
    "        for j in range(i + 1, starting_nodes + 1):\n",
    "            network.add_edge(i, j)\n",
    "    \n",
    "    V = np.array([initialise_weight(G) for i in range(starting_nodes)])\n",
    "    \n",
    "    #return network\n",
    "    return network, V\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "def precompute_sigmas(sigma, num_epochs):\n",
    "    \n",
    "    return np.array([sigma * np.exp(-2 * sigma * e / num_epochs)\n",
    "                     for e in range(num_epochs)])\n",
    "\n",
    "##########################################################################################################################\n",
    "##TODO\n",
    "# function to train SOM on given graph\n",
    "def train_network(G, network, V, num_epochs, eta, precomputed_sigmas, \n",
    "                  precomputed_graph_shortest_paths, precomputed_graph_shortest_path_lengths):\n",
    "    \n",
    "    #list if all patterns to visit\n",
    "    training_patterns = range(len(G))\n",
    "    \n",
    "    #shortest path matrix\n",
    "    shortest_path = np.array(nx.floyd_warshall_numpy(network))\n",
    "    \n",
    "    net_change = np.zeros(len(network))\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        \n",
    "        #shuffle nodes\n",
    "        np.random.shuffle(training_patterns)\n",
    "        \n",
    "        sigma = precomputed_sigmas[e]\n",
    "        \n",
    "        # iterate through N nodes of graph\n",
    "        for i in training_patterns:\n",
    "            \n",
    "            #data point to consider\n",
    "            x = G.nodes()[i]\n",
    "            \n",
    "            #determine winning neuron\n",
    "            closest_neuron = winning_neuron(x, V, precomputed_graph_shortest_path_lengths)\n",
    "            \n",
    "            # update weights\n",
    "            V, deltaV = update_weights(x, V, closest_neuron, shortest_path[closest_neuron], eta, precomputed_sigmas[e],\n",
    "                              precomputed_graph_shortest_paths, precomputed_graph_shortest_path_lengths)\n",
    "            \n",
    "            net_change += deltaV\n",
    "            \n",
    "    print \"NET CHANGE AFTER TRAINING\"\n",
    "    print net_change\n",
    "\n",
    "    return V\n",
    "        \n",
    "##########################################################################################################################\n",
    "\n",
    "def distance(x, v, precomputed_graph_shortest_path_lengths):\n",
    "    beta = np.float(v[2])\n",
    "    return min(precomputed_graph_shortest_path_lengths[v[0]][x] + beta, \n",
    "               precomputed_graph_shortest_path_lengths[v[1]][x] + 1 - beta)\n",
    "\n",
    "# winning neuron\n",
    "def winning_neuron(x, V, precomputed_graph_shortest_path_lengths):\n",
    "    \n",
    "    distances = np.array([distance(x, v, precomputed_graph_shortest_path_lengths) for v in V])\n",
    "    \n",
    "    return distances.argmin()\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "\n",
    "# function to update weights\n",
    "def update_weights(x, V, winning_neuron, shortest_path_length, eta, sigma, \n",
    "                   precomputed_graph_shortest_paths, precomputed_graph_shortest_path_lengths):\n",
    "    \n",
    "    #weight update (vectorised)\n",
    "    deltaV = np.dot(np.diag(eta * np.exp(- shortest_path_length ** 2 / (2 * sigma ** 2))), \n",
    "                      np.array([distance(x, v, precomputed_graph_shortest_path_lengths) for v in V]))\n",
    "    \n",
    "    V = np.array([move_along_shortest_path(x, v, deltav, precomputed_graph_shortest_paths,\n",
    "                                           precomputed_graph_shortest_path_lengths) for v, deltav in zip(V, deltaV)])\n",
    "    \n",
    "    return V, deltaV\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "def move_along_shortest_path(x, v, deltaV, precomputed_graph_shortest_paths, \n",
    "                             precomputed_graph_shortest_path_lengths):\n",
    "    \n",
    "    #unpack v\n",
    "    vi, vj, beta = v\n",
    "    beta = np.float(beta)\n",
    "    \n",
    "    #weight of edge between vi and vj\n",
    "    weight = precomputed_graph_shortest_path_lengths[vi][vj]\n",
    "    \n",
    "    #check if passing through vi or vj is quicker\n",
    "    if precomputed_graph_shortest_path_lengths[x][vi] + beta * weight < \\\n",
    "    precomputed_graph_shortest_path_lengths[x][vj] + (1 - beta) * weight:\n",
    "        \n",
    "        #passing through vi is quicker\n",
    "        beta = 1 - beta\n",
    "        path = [vj, vi]\n",
    "        path.extend(precomputed_graph_shortest_paths[vi][x])\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        #passing through vj is quicker\n",
    "        path = [vi, vj]\n",
    "        path.extend(precomputed_graph_shortest_paths[vj][x])\n",
    "\n",
    "    #move along path until deltaV is less than edge weight\n",
    "    for vi, vj in zip(path, path[1:]):\n",
    "        \n",
    "        #edge weight\n",
    "        weight = precomputed_graph_shortest_path_lengths[vi][vj]\n",
    "\n",
    "        if deltaV <  weight * (1 - beta):\n",
    "            return vi, vj, beta + deltaV / weight\n",
    "        \n",
    "        #decrease deltaV by (1 - beta of edge weight)\n",
    "        deltaV -= weight * (1 - beta)\n",
    "        beta = 0\n",
    "        \n",
    "    return x, x, 0\n",
    "\n",
    "#########################################################################################################################\n",
    "                                 \n",
    "# def move_along_shortest_path(x, v, deltaV, precomputed_graph_shortest_paths, \n",
    "#                              precomputed_graph_shortest_path_lengths):\n",
    "    \n",
    "#     #unpack v\n",
    "#     vi, vj, beta = v\n",
    "#     beta = np.float(beta)\n",
    "    \n",
    "#     # four cases to consider\n",
    "#     if precomputed_graph_shortest_path_lengths[x][vi] + \\\n",
    "#     beta * precomputed_graph_shortest_path_lengths[vi][vj] < \\\n",
    "#     precomputed_graph_shortest_path_lengths[x][vj] + \\\n",
    "#     (1 - beta) * precomputed_graph_shortest_path_lengths[vi][vj]:\n",
    "        \n",
    "#         # moving towards vi\n",
    "#         #two cases here -- do we stay within (vi,vj) or move to next node?\n",
    "        \n",
    "#         if deltaV < beta * precomputed_graph_shortest_path_lengths[vi][vj]:\n",
    "            \n",
    "#             # can safely move towards vi\n",
    "#             new_beta = (beta * precomputed_graph_shortest_path_lengths[vi][vj] - deltaV) / \\\n",
    "#             precomputed_graph_shortest_path_lengths[vi][vj]\n",
    "            \n",
    "#             return vi, vj, new_beta\n",
    "        \n",
    "#         else:\n",
    "            \n",
    "#             # we are moving towards vi but have passed it -- so now we must adjust vi, vj and beta\n",
    "            \n",
    "#             # finding new vi and vj\n",
    "#             # how far past vi have we moved?\n",
    "#             d = deltaV - beta * precomputed_graph_shortest_path_lengths[vi][vj]\n",
    "            \n",
    "#             # next, we will find the next node in the shortest path \n",
    "#             path = precomputed_graph_shortest_paths[vi][x]\n",
    "            \n",
    "#             i = 0;\n",
    "#             # vj will be second on the shortest path from vi to x\n",
    "#             new_vi = path[i]\n",
    "#             new_vj = path[min(i+1, len(path) - 1)]\n",
    "            \n",
    "#             # keep moving vi and vj along path until remaining distance to move (d)\n",
    "#             # is less than dist[new_vi][new_vj]\n",
    "#             while d > precomputed_graph_shortest_path_lengths[new_vi][new_vj]:\n",
    "                \n",
    "#                 #reached target\n",
    "#                 if new_vi == x or new_vj == x:\n",
    "                    \n",
    "#                     # set weight to be input vector\n",
    "                    \n",
    "#                     #set new vi to be input vector\n",
    "#                     new_vi = x\n",
    "                    \n",
    "#                     new_vj = x\n",
    "                    \n",
    "#                     d = 0\n",
    "                    \n",
    "#                     break\n",
    "                \n",
    "#                 # subtract distance between vi and vj\n",
    "#                 d -= precomputed_graph_shortest_path_lengths[new_vi][new_vj]\n",
    "                \n",
    "#                 # increment i\n",
    "#                 i += 1\n",
    "                \n",
    "#                 # update vi, vj\n",
    "#                 new_vi = path[i]\n",
    "#                 new_vj = path[i+1]\n",
    "                \n",
    "#             # now d < dist[new_vi][new_vj]\n",
    "            \n",
    "#             # calculate new beta \n",
    "#             #new_beta = (distance_function(new_vi, v) + beta * \\\n",
    "#             #            dist[vi][vj] - move_distance) / distance_function(new_vi, v)\n",
    "#             new_beta = d / precomputed_graph_shortest_path_lengths[new_vi][new_vj]\n",
    "            \n",
    "#             return new_vi, new_vj, new_beta\n",
    "            \n",
    "#     else:\n",
    "\n",
    "#         #moving towards vj\n",
    "#         #two cases here -- do we stay within (vi,vj) or move to next node?\n",
    "\n",
    "#         if deltaV < (1 - beta) * precomputed_graph_shortest_path_lengths[vi][vj]:\n",
    "\n",
    "#             #can move safely towards vj\n",
    "#             new_beta = (beta * precomputed_graph_shortest_path_lengths[vi][vj] + deltaV) / \\\n",
    "#             precomputed_graph_shortest_path_lengths[vi][vj]\n",
    "\n",
    "#             return vi, vj, new_beta\n",
    "\n",
    "#         else:\n",
    "\n",
    "#             # we are moving towards vj but have passed it -- so now we must adjust vi, vj and beta\n",
    "\n",
    "#             # finding vi and vj\n",
    "#             # how far past vj have we moved?\n",
    "#             d = deltaV - (1 - beta) * precomputed_graph_shortest_path_lengths[vi][vj]\n",
    "\n",
    "#             # next, we will find the next node in the shortest path \n",
    "#             path = precomputed_graph_shortest_paths[vj][x]\n",
    "\n",
    "#             # initialise list index i\n",
    "#             i = 0;\n",
    "            \n",
    "#             # vj will be second on the shortest path from vj to x\n",
    "#             new_vi = path[i]\n",
    "#             new_vj = path[min(i+1, len(path) - 1)]\n",
    "\n",
    "#             # keep moving vi and vj along path until remaining distance to move (d)\n",
    "#             # is less than dist[new_vi, new_vj]\n",
    "#             while d > precomputed_graph_shortest_path_lengths[new_vi][new_vj]:\n",
    "                \n",
    "#                 #reached target\n",
    "#                 if new_vi == x or new_vj == x:\n",
    "                    \n",
    "#                     # set weight to be input vector\n",
    "                    \n",
    "#                     #set new vi to be input vector\n",
    "#                     new_vi = x\n",
    "                    \n",
    "#                     #\n",
    "#                     new_vj = x\n",
    "                    \n",
    "#                     #\n",
    "#                     d = 0\n",
    "                    \n",
    "#                     break\n",
    "\n",
    "#                 #subtract distance between vi and vj\n",
    "#                 d -= precomputed_graph_shortest_path_lengths[new_vi][new_vj]\n",
    "\n",
    "#                 # increment i\n",
    "#                 i += 1\n",
    "                \n",
    "#                 # move vi and vj along path\n",
    "#                 new_vi = path[i]\n",
    "#                 new_vj = path[i+1]\n",
    "\n",
    "#             # now d < dist[new_vi, new_vj]\n",
    "\n",
    "#             # calculate new beta \n",
    "#             #new_beta = (distance_function(new_vi, v) + (beta) * \\\n",
    "#             #            dist[vi][vj] - move_distance) / distance_function(new_vi, v)\n",
    "#             new_beta = d / precomputed_graph_shortest_path_lengths[new_vi][new_vj]\n",
    "\n",
    "#         return new_vi, new_vj, new_beta\n",
    "\n",
    "########################################################################################################################   \n",
    "                                 \n",
    "\n",
    "                                 \n",
    "# assign nodes into clusters\n",
    "def assign_nodes(G, network, V, precomputed_graph_shortest_path_lengths):\n",
    "    \n",
    "    #distance from each datapoint (row) to each weight vector (column)\n",
    "    distances = np.array([[distance(x, v, precomputed_graph_shortest_path_lengths) for v in V] for x in G.nodes()])\n",
    "    \n",
    "    #index of column giving minimum distance\n",
    "    arg_min_distances = np.argmin(distances, axis=1)\n",
    "    \n",
    "    #minium distance for each datapoint\n",
    "    min_distances = np.diagonal(np.take(distances, arg_min_distances, axis=1))\n",
    "    \n",
    "    #nodes corresponding to minimum index (of length len(X))\n",
    "    minimum_nodes = np.array([network.nodes()[n] for n in arg_min_distances])\n",
    "    \n",
    "    #list of neurons with no assignments\n",
    "    empty_neurons = np.array([n for n in network.nodes() if n not in minimum_nodes])\n",
    "    \n",
    "    if empty_neurons.size > 0:\n",
    "    \n",
    "        ################################################DELETION####################################################\n",
    "        \n",
    "        print \"DELETING NODES: {}\".format(empty_neurons)\n",
    "\n",
    "        #neighbours of deleted neurons\n",
    "        neighbour_lists = np.array([network.neighbors(n) for n in empty_neurons])\n",
    "        \n",
    "        #remove the nodes\n",
    "        network.remove_nodes_from(empty_neurons)\n",
    "        \n",
    "        ##remove from V\n",
    "        V = np.array([V[i] for i in range(len(V)) if i in arg_min_distances])\n",
    "        \n",
    "        #compute distances between all neurons in input space\n",
    "        computed_neuron_distances = compute_neuron_distances(network, V, precomputed_graph_shortest_path_lengths)\n",
    "        \n",
    "        ##connect separated components\n",
    "        for neighbour_list in neighbour_lists:\n",
    "            connect_components(network, neighbour_list, computed_neuron_distances)\n",
    "\n",
    "        ############################################################################################################\n",
    "\n",
    "    #array of errors\n",
    "    errors = np.array([np.mean(min_distances[minimum_nodes == n]) for n in network.nodes()])\n",
    "    \n",
    "    #compute MQE\n",
    "    MQE = np.mean(errors)\n",
    "    \n",
    "    #array of assignments\n",
    "    assignments = np.array([np.array([G.nodes()[i] for i in np.where(minimum_nodes == n)[0]]) for n in network.nodes()])\n",
    "    \n",
    "    #zip zith nodes\n",
    "    errors = {n: e for n, e in zip(network.nodes(), errors)}\n",
    "    assignments = {n: a for n, a in zip(network.nodes(), assignments)}\n",
    "    \n",
    "    nx.set_node_attributes(network, \"e\", errors)\n",
    "    nx.set_node_attributes(network, \"ls\", assignments)\n",
    "    \n",
    "    return MQE, empty_neurons.size, V\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "def neuron_distances(v1, v2, precomputed_graph_shortest_path_lengths):\n",
    "    beta = np.float(v1[2])\n",
    "    return min(distance(v1[0], v2, precomputed_graph_shortest_path_lengths) + beta,\n",
    "              distance(v1[1], v2, precomputed_graph_shortest_path_lengths) + 1 - beta)\n",
    "                                 \n",
    "                                 \n",
    "def compute_neuron_distances(network, V, precomputed_graph_shortest_path_lengths):\n",
    "    \n",
    "    distances = np.array([[neuron_distances(v1, v2, precomputed_graph_shortest_path_lengths) for v2 in V] for v1 in V])\n",
    "    \n",
    "    return {network.nodes()[i] : {network.nodes()[j] : distances[i, j] for j in range(len(distances[i]))}\n",
    "           for i in range(len(distances))}\n",
    "    \n",
    "######################################################################################################################### \n",
    "\n",
    "\n",
    "def connect_components(network, neighbour_list, computed_neuron_distances):\n",
    "    \n",
    "    sub_network = network.subgraph(neighbour_list)\n",
    "    \n",
    "    connected_components = [sub_network.subgraph(c) for c in nx.connected_components(sub_network)]\n",
    "    number_of_connected_components = len(connected_components)\n",
    "    \n",
    "    for i in range(number_of_connected_components):\n",
    "        \n",
    "        connected_component_1 = connected_components[i].nodes()\n",
    "        \n",
    "        for j in range(i + 1, number_of_connected_components):\n",
    "            \n",
    "            connected_component_2 = connected_components[j].nodes()\n",
    "            \n",
    "            distances = np.array([[computed_neuron_distances[n1][n2] for n2 in connected_component_2]\n",
    "                                 for n1 in connected_component_1])\n",
    "            \n",
    "            min_n1, min_n2 = np.unravel_index(distances.argmin(), distances.shape)\n",
    "            \n",
    "            network.add_edge(connected_component_1[min_n1], \n",
    "                            connected_component_2[min_n2])\n",
    "\n",
    "##########################################################################################################################\n",
    "            \n",
    "##function to identify neuron with greatest error\n",
    "def identify_error_unit(network):\n",
    "    \n",
    "    number_of_assignments = {k: len(v) for k, v in nx.get_node_attributes(network, \"ls\").items()}\n",
    "    errors = nx.get_node_attributes(network, \"e\")\n",
    "    \n",
    "    errors = {k: v for k, v in errors.items() if number_of_assignments[k] > 1}\n",
    "    \n",
    "    return max(errors, key=errors.get)\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "def expand_network(ID, G, network, V, error_unit, precomputed_graph_shortest_path_lengths):\n",
    "    \n",
    "    #v goes to random vector in range of error unit\n",
    "    ls = network.node[error_unit][\"ls\"]  \n",
    "    \n",
    "    #weight of new neuron\n",
    "    w = initialise_weight(G.subgraph(ls))\n",
    "    \n",
    "    #zip nodes and distances\n",
    "    distances = zip(network.nodes(), np.array([neuron_distances(w, v, \n",
    "                    precomputed_graph_shortest_path_lengths) for v in V]))\n",
    "        \n",
    "    #identify neighbour pointing closet\n",
    "    error_unit_neighbours = network.neighbors(error_unit)\n",
    "\n",
    "    #id of new node\n",
    "    new_node = max(network) + 1\n",
    "    \n",
    "    #add new node to map\n",
    "    network.add_node(new_node)\n",
    "    \n",
    "    ##id\n",
    "    network.node[new_node][\"ID\"] = \"{}-{}\".format(ID, str(new_node).zfill(2))\n",
    "    \n",
    "    #add edges to map\n",
    "    \n",
    "    #connect error unit and new node\n",
    "    network.add_edge(error_unit, new_node)\n",
    "    \n",
    "    if len(error_unit_neighbours) > 0:\n",
    "        \n",
    "        ##find closest neighbour\n",
    "        distances = {n: v for n, v in distances if n in error_unit_neighbours}\n",
    "        closest_neighbour = min(distances, key=distances.get)\n",
    "        \n",
    "        #connect to error unit and closest neighbour\n",
    "        network.add_edge(closest_neighbour, new_node)\n",
    "        \n",
    "    #add v to V\n",
    "    V = np.vstack([V, w])   \n",
    "    \n",
    "    return V\n",
    "        \n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "\n",
    "##GHSOM algorithm\n",
    "def ghsom(ID, G, num_iter, eta, sigma, e_0, e_sg, e_en, q):\n",
    "    \n",
    "    print \"MQE_0={}, growth_target={}\".format(e_0, e_0 * e_sg)\n",
    "    \n",
    "    precomputed_graph_shortest_paths = nx.shortest_path(G)\n",
    "    precomputed_graph_shortest_path_lengths = {n1 : \n",
    "            {n2 : len(precomputed_graph_shortest_paths[n1][n2]) for n2 in precomputed_graph_shortest_paths.keys()}\n",
    "                                              for n1 in precomputed_graph_shortest_paths.keys()}\n",
    "    \n",
    "    print \"computed shortest paths\"\n",
    "    \n",
    "    if e_0 == np.inf:\n",
    "        starting_nodes = 1\n",
    "    else:\n",
    "        starting_nodes = 3\n",
    "        \n",
    "    #create som for this neuron\n",
    "    network, V = initialise_network(ID, G, starting_nodes=starting_nodes)\n",
    "    \n",
    "    print \"initialised network\"\n",
    "    \n",
    "    #precompute sigmas\n",
    "    precomputed_sigmas = precompute_sigmas(sigma, num_iter)\n",
    "    \n",
    "    print \"precomputed sigmas\"\n",
    "    \n",
    "    #train for lamda epochs\n",
    "    V = train_network(G, network, V, num_iter, eta, precomputed_sigmas, precomputed_graph_shortest_paths,\n",
    "                      precomputed_graph_shortest_path_lengths)\n",
    "    \n",
    "    print \"trained network\"\n",
    "    \n",
    "    #classify nodes and compute error\n",
    "    MQE, num_deleted_neurons, V = assign_nodes(G, network, V, precomputed_graph_shortest_path_lengths)\n",
    "    \n",
    "    print \"assigned nodes MQE={}, target={}\".format(MQE, e_0 * e_sg)\n",
    "    \n",
    "    ##som growth phase\n",
    "    #repeat until error is low enough\n",
    "    while MQE > e_sg * e_0 and num_deleted_neurons < MAX_DELETED_NEURONS:\n",
    "        \n",
    "        #find neuron with greatest error\n",
    "        error_unit = identify_error_unit(network)\n",
    "        \n",
    "        print \"identified error unit: {}\".format(error_unit)\n",
    "        \n",
    "        #expand network\n",
    "        V = expand_network(ID, G, network, V, error_unit, precomputed_graph_shortest_path_lengths)\n",
    "        \n",
    "        print \"expanded network\"\n",
    "        \n",
    "        #train for lam epochs\n",
    "        V = train_network(G, network, V, num_iter, eta, precomputed_sigmas, precomputed_graph_shortest_paths,\n",
    "                      precomputed_graph_shortest_path_lengths)\n",
    "        \n",
    "        print \"trained network\"\n",
    "\n",
    "        #calculate mean network error\n",
    "        MQE, deleted_neurons, V = assign_nodes(G, network, V, precomputed_graph_shortest_path_lengths)\n",
    "        num_deleted_neurons += deleted_neurons\n",
    "        \n",
    "        print \"assigned nodes MQE={}, target={}\".format(MQE, e_0 * e_sg)\n",
    "        \n",
    "    print \"growth terminated, MQE: {}, target: {}, number of deleted neurons: {}\".format(MQE, e_0 * e_sg, num_deleted_neurons)\n",
    "        \n",
    "    ##neuron expansion phase\n",
    "    #iterate thorugh all neruons and find neurons with error great enough to expand\n",
    "    for _, d in network.nodes(data=True):\n",
    "        \n",
    "        #unpack\n",
    "        node_id = d[\"ID\"]\n",
    "        ls = d[\"ls\"]\n",
    "        e = d[\"e\"]\n",
    "        \n",
    "        #check error\n",
    "        if e_0 == np.inf or (e > e_en * e_0 and len(ls) > MIN_EXPANSION_SIZE and num_deleted_neurons < MAX_DELETED_NEURONS):\n",
    "            \n",
    "            if e_0 == np.inf:\n",
    "                node_id = \"01\"\n",
    "                \n",
    "            H = G.subgraph(ls)\n",
    "            \n",
    "            print \"submitted job: ID={}, e={}, number of nodes={}\".format(node_id, e, len(ls))\n",
    "            \n",
    "            #add these parameters to the queue\n",
    "            q.put((node_id, H, num_iter, eta, sigma, e, e_sg, e_en))\n",
    "    \n",
    "    #return network\n",
    "    return network, MQE\n",
    "\n",
    "##########################################################################################################################\n",
    "##########################################################################################################################\n",
    "\n",
    "def label_nodes(G, networks):\n",
    "    \n",
    "    for _, network, _ in networks: \n",
    "        \n",
    "        for _, d in network.nodes(data=True):\n",
    "            \n",
    "            community = d[\"ID\"]\n",
    "            layer = community.count(\"-\")\n",
    "            assignment_string = \"assigned_community_layer_{}\".format(layer)\n",
    "            \n",
    "            for node in d[\"ls\"]:\n",
    "                \n",
    "                G.node[node][assignment_string] = community\n",
    "\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "def NMI_one_layer(G, label, layer):\n",
    "    \n",
    "    #actual community for this layer\n",
    "    actual_community_labels = np.array([v for k, v in nx.get_node_attributes(G, label).items()])\n",
    "    \n",
    "    #predicted communitiy for this layer\n",
    "    predicted_community_labels = np.array([v for k, v in nx.get_node_attributes(G, \n",
    "         \"assigned_community_layer_{}\".format(layer)).items()])\n",
    "\n",
    "    print actual_community_labels\n",
    "    print predicted_community_labels\n",
    "    \n",
    "    return met.normalized_mutual_info_score(actual_community_labels, predicted_community_labels)\n",
    "\n",
    "def NMI_all_layers(G, labels):\n",
    "    \n",
    "    return np.array([NMI_one_layer(G, labels[i], i + 1) for i in range(len(labels))])\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "## get embedding TERRIBLE but staying\n",
    "def get_embedding(G):\n",
    "    \n",
    "#     #get number of niodes in the graph\n",
    "#     num_nodes = nx.number_of_nodes(G)\n",
    "    \n",
    "#     #dimension of embedding\n",
    "#     dim = 0\n",
    "#     while 'embedding'+str(dim) in G.node[G.nodes()[0]]:\n",
    "#         dim += 1\n",
    "    \n",
    "#     #initialise embedding\n",
    "#     X = np.array([[d[\"embedding{}\".format(j)] for j in range(dim)] for n, d in G.nodes(data=True)])\n",
    "\n",
    "    return np.array([v for k, v in nx.get_node_attributes(G, \"embedding\").items()])\n",
    "\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "def process_job(q, networks):\n",
    "    \n",
    "    #unpack first element of queue\n",
    "    #contains all the para,eters for GHSOM\n",
    "    ID, G, num_iter, eta, sigma, e_0, e_sg, e_en = q.get()\n",
    "\n",
    "    #run GHSOM and return a network and MQE\n",
    "    n, e = ghsom(ID, G, num_iter, eta, sigma, e_0, e_sg, e_en, q)\n",
    "\n",
    "    #append result to networks list\n",
    "    networks.append((ID, n, e))\n",
    "\n",
    "    #mark task as done\n",
    "    q.task_done()\n",
    "\n",
    "def worker(q, networks):\n",
    "    \n",
    "    #continually poll queue for jobs \n",
    "    while True:\n",
    "        process_job(q, networks)\n",
    "\n",
    "def main(params, filename, num_iter=10000, num_threads=1):\n",
    "    \n",
    "    #network\n",
    "    G = nx.read_gpickle(filename)\n",
    "    \n",
    "    ##list of returned networks\n",
    "    networks = []\n",
    "    \n",
    "    #initilise worker queue\n",
    "    q = Queue()\n",
    "    \n",
    "    #add initial layer of ghsom to queue\n",
    "    q.put((\"00\", G, num_iter, params[\"eta\"], params[\"sigma\"], np.inf, params[\"e_sg\"], params[\"e_en\"]))\n",
    "    \n",
    "    if num_threads > 1:\n",
    "    \n",
    "        #initialise threads\n",
    "        for i in range(num_threads):\n",
    "\n",
    "            t = Thread(target=worker, args=(q, networks))\n",
    "            t.setDaemon(True)\n",
    "            t.start()\n",
    "\n",
    "        #finally wait until queue is empty and all tasks are done\n",
    "        q.join()\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        #single thread\n",
    "        while not q.empty():\n",
    "            process_job(q, networks)\n",
    "    \n",
    "    print \"DONE\"\n",
    "    \n",
    "    return G, networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# params = {'eta': 0.0001,\n",
    "#          'sigma': 1,\n",
    "#           'e_sg': 0.7,\n",
    "#          'e_en': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %prun G, networks = main(params=params, filename=\"embedded_benchmark.gpickle\", num_threads=1, num_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# label_nodes(G, networks[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NMI_all_layers(G, labels=[\"firstlevelcommunity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# _, network, _ = networks[1]\n",
    "# colours = np.random.rand(len(network), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualise_graph(G=G, colours=colours, layer=1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

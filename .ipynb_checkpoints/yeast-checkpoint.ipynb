{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data=yeast_reactome\n",
      "\n",
      "e_sg=0.3\n",
      "\n",
      "e_en=0.3\n",
      "\n",
      "running GHSOM and saving to yeast_reactome_hierarchy_communities_0.3_0.3.pkl\n",
      "MQE_0=2.63087453752, growth target=0.789262361257\n",
      "MQE=0.805284150402, size of map=3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d0dc746a29c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mghsom_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../embedded_{}.gpickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0msave_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\nnumber of communities found: {}, saved maps to {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mghsom_parallel.pyc\u001b[0m in \u001b[0;36mmain\u001b[0;34m(params, filename, lam, num_threads)\u001b[0m\n",
      "\u001b[0;32mghsom_parallel.pyc\u001b[0m in \u001b[0;36mprocess_job\u001b[0;34m(q, networks)\u001b[0m\n",
      "\u001b[0;32mghsom_parallel.pyc\u001b[0m in \u001b[0;36mghsom\u001b[0;34m(ID, named_X, lam, eta, sigma, e_0, e_sg, e_en, q)\u001b[0m\n",
      "\u001b[0;32mghsom_parallel.pyc\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(X, network, V, num_epochs, eta_0, precomputed_sigmas)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import Queue\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ghsom import main_no_labels as ghsom_main\n",
    "# from ghsom_parallel import main as ghsom_main\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "# def add(d, key, value):\n",
    "#     if key in d:\n",
    "#         d[key].append(value)\n",
    "#     else:\n",
    "#         d.update({key : [value]})\n",
    "    \n",
    "root_dir = \"/home/david/Documents/ghsom/hierarchical_exploration\"\n",
    "\n",
    "# for data in [\"yeast_reactome\", \"yeast_uetz\", \"collins\", \"ccsb\", \"ito_core\", \"lc_multiple\"]:\n",
    "for data in [\"yeast_reactome\"]:\n",
    "    \n",
    "    print \"data={}\".format(data)\n",
    "    print\n",
    "    \n",
    "#     for e_sg in [0.7, 0.6, 0.5, 0.4]:\n",
    "    for e_sg in [0.3]:\n",
    "        \n",
    "        print \"e_sg={}\".format(e_sg)\n",
    "        print\n",
    "\n",
    "#         for e_en in [0.7, 0.6, 0.5, 0.4, 0.3]:\n",
    "        for e_en in [0.3]:\n",
    "\n",
    "            print \"e_en={}\".format(e_en)\n",
    "            print\n",
    "\n",
    "            os.chdir(root_dir)\n",
    "\n",
    "            #ghsom parameters\n",
    "            params = {'eta': 0.001,\n",
    "                     'sigma': 1,\n",
    "                      'e_sg': e_sg,\n",
    "                     'e_en': e_en}\n",
    "\n",
    "            map_file = '{}_hierarchy_communities_{}_{}'.format(data, e_sg, e_en)\n",
    "\n",
    "            if not os.path.isfile(\"{}.pkl\".format(map_file)):\n",
    "\n",
    "                #run ghsom and save output\n",
    "                print \"running GHSOM and saving to {}.pkl\".format(map_file)\n",
    "\n",
    "\n",
    "\n",
    "                G, map = ghsom_main(params, '../embedded_{}.gpickle'.format(data), lam=1000)\n",
    "                save_obj((G, map), map_file)\n",
    "                print '\\nnumber of communities found: {}, saved maps to {}'.format(len(map), map_file)\n",
    "\n",
    "#                 G, networks = ghsom_main(params, '../embedded_{}.gpickle'.format(data), lam=1000, num_threads=5)\n",
    "#                 save_obj((G, networks), map_file)\n",
    "#                 print '\\nnumber of maps grown: {}, saved maps to {}'.format(len(networks), map_file)\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "                print \"{}.pkl already exists, loading maps\".format(map_file)    \n",
    "                #load output\n",
    "                G, map = load_obj(map_file)\n",
    "#                 G, networks = load_obj(map_file)\n",
    "\n",
    "            #save results to file\n",
    "            dir_name = \"{}_hierarchy_communities_{}_{}\".format(data, e_sg, e_en)\n",
    "            if not os.path.isdir(dir_name):\n",
    "#                 shutil.rmtree(dir_name)\n",
    "\n",
    "                os.mkdir(dir_name)\n",
    "                print 'made directory {}'.format(dir_name)\n",
    "\n",
    "            os.chdir(dir_name)\n",
    "            print \"moved to {}\".format(dir_name)\n",
    "\n",
    "            #all genes\n",
    "            all_genes_file = \"all_genes.txt\"\n",
    "            with open(all_genes_file, 'w') as f:\n",
    "                for n, d in G.nodes(data=True):\n",
    "                    f.write(\"{}\\n\".format(n))\n",
    "            print \"wrote {}\".format(all_genes_file)\n",
    "            \n",
    "            genes = G.nodes()\n",
    "            gene_assignments = {k: v for k, v in zip(genes, \n",
    "                np.array([[\"\" for j in range(10)] for i in range(len(genes))], dtype=\"S20\"))}\n",
    "            \n",
    "#             for id, network, e in networks:\n",
    "\n",
    "#                 #shortest path matrix\n",
    "#                 shortest_path = nx.floyd_warshall_numpy(network)\n",
    "#                 communities_in_this_map = np.array([v for k, v in nx.get_node_attributes(network, \"ID\").items()])\n",
    "#                 shortest_path_df = pd.DataFrame(shortest_path, index=communities_in_this_map)\n",
    "#                 shortest_path_file = \"{}_shortest_path.csv\".format(id)\n",
    "                \n",
    "#                 shortest_path_df.to_csv(shortest_path_file, index=True, header=False, sep=',')\n",
    "#                 print 'wrote shortest path matrix and saved as {}'.format(shortest_path_file)\n",
    "\n",
    "#                 for n, d in network.nodes(data=True):\n",
    "                    \n",
    "#                     community_assignment = d[\"ID\"]\n",
    "#                     layer = community_assignment.count(\"-\")\n",
    "                    \n",
    "#                     for node in d[\"ls\"]:\n",
    "#                         gene_assignments[node][layer] = community_assignment\n",
    "\n",
    "            #map queue\n",
    "            q = Queue.Queue()\n",
    "\n",
    "            c = 1\n",
    "            depth = 0\n",
    "            q.put((c, depth, map))\n",
    "\n",
    "            genes = G.nodes()\n",
    "            gene_assignments = {k: v for k, v in zip(genes, \n",
    "                np.array([[\"\" for j in range(10)] for i in range(len(genes))], dtype=\"S20\"))}\n",
    "\n",
    "            while not q.empty():\n",
    "\n",
    "                map_id, depth, map = q.get()\n",
    "                c = 1\n",
    "\n",
    "                #shortest path matrix\n",
    "                communities_in_this_map = np.array([\"{}-{}\".format(str(map_id).zfill(2), \n",
    "                                                                   str(i).zfill(2)) for i in range(c, c + len(map))])\n",
    "\n",
    "                shortest_path = nx.floyd_warshall_numpy(map).astype(np.int)\n",
    "    #             shortest_path = np.insert(shortest_path, 0, communities_in_this_map, axis=1)\n",
    "                shortest_path_df = pd.DataFrame(shortest_path, index=communities_in_this_map)\n",
    "                shortest_path_file = \"{}_shortest_path.csv\".format(str(map_id).zfill(2))\n",
    "    #             np.savetxt(shortest_path_file, shortest_path, fmt='%i', delimiter=\",\")\n",
    "                shortest_path_df.to_csv(shortest_path_file, index=True, header=False, sep=',')\n",
    "                print 'wrote shortest path matrix and saved as {}'.format(shortest_path_file)\n",
    "\n",
    "\n",
    "\n",
    "                #gene community assignments\n",
    "                for n, d in map.nodes(data=True):\n",
    "\n",
    "                    community = communities_in_this_map[c - 1]\n",
    "\n",
    "                    for node in d['ls']:\n",
    "                        gene_assignments[node][depth] = community\n",
    "\n",
    "                    #add map to queue\n",
    "                    m = d['n']\n",
    "\n",
    "                    if not m == []:\n",
    "\n",
    "                        q.put((community, depth + 1, m))   \n",
    "\n",
    "                    c += 1\n",
    "\n",
    "            #back to matrix\n",
    "            assignment_matrix = np.array([v for k, v in gene_assignments.items()])\n",
    "            #remove unnecessary columns\n",
    "            mask = assignment_matrix != \"\"\n",
    "            idx = mask.any(axis = 0)\n",
    "            assignment_matrix = assignment_matrix[:,idx]\n",
    "            assignment_matrix = np.insert(assignment_matrix, 0, \"01\", axis=1)\n",
    "\n",
    "            assignment_df = pd.DataFrame(assignment_matrix, index=genes)\n",
    "\n",
    "            assignment_file = \"assignment_matrix.csv\"\n",
    "        \n",
    "            assignment_df.to_csv(assignment_file, index=True, header=False, sep=',')\n",
    "\n",
    "#             np.savetxt(assignment_matrix_file, assignment_matrix, delimiter=\",\", fmt=\"%s\")\n",
    "            print \"wrote assignment matrix and saved it as {}\".format(assignment_file)\n",
    "            print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

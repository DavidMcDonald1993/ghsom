{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##function to compute DSD matrix using AMG method\n",
    "#N: laplacian matrix\n",
    "#d: list of degrees\n",
    "#v: smallest eigenvector\n",
    "def dsd(N, d, v):\n",
    "    \n",
    "    #number of nodes in G\n",
    "    n = len(N)\n",
    "    \n",
    "    #initialize dsd matrix\n",
    "    dsd = np.zeros((n, n))\n",
    "    \n",
    "    #B\n",
    "    B = np.diag(d ** -0.5) @ np.identity(n)\n",
    "    \n",
    "    #compute G\n",
    "    G = compute_gr(N, B, d, v)\n",
    "    \n",
    "    print('computed greens matrix')\n",
    "    \n",
    "    #compute dsd for each pair\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            \n",
    "            #compute distance\n",
    "            dis = np.linalg.norm(np.transpose(B[:,i] - B[:,j]) @ G, ord=1)\n",
    "            \n",
    "            #add to dsd matrix\n",
    "            dsd[i,j] = dis\n",
    "            dsd[j,i] = dis\n",
    "    \n",
    "    #return\n",
    "    return dsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##dsd embedding\n",
    "def dsd_embedding(G):\n",
    "    \n",
    "    #number of nodes in the graph\n",
    "    n = nx.number_of_nodes(G)\n",
    "    \n",
    "    #adjacency matrix\n",
    "    A = nx.adjacency_matrix(G).toarray()\n",
    "    \n",
    "    #list of degrees\n",
    "    deg = np.sum(A, axis=1)\n",
    "    \n",
    "    #normalised graph laplacian\n",
    "    N = np.identity(n) - np.diag(deg ** -0.5) @ A @ np.diag(deg ** -0.5)\n",
    "    \n",
    "    print('constructed normalised laplacian')\n",
    "    \n",
    "    #eigen decompose normalised laplacian\n",
    "    l, U = np.linalg.eigh(N)\n",
    "    \n",
    "    ##sort eigenvalues (and eigenvectors) into ascending order\n",
    "    idx = l.argsort()\n",
    "    l = l[idx]\n",
    "    U = U[:,idx]\n",
    "    \n",
    "    #compute dsd matrix as metric\n",
    "    D = dsd(N, deg, U[:,0]) \n",
    "    \n",
    "    print('computed dsd matrix')\n",
    "    \n",
    "    #centreing matrix\n",
    "    C = np.identity(n) - np.ones((n, n)) / n\n",
    "    \n",
    "    #similarity matrix\n",
    "    K = - 1/2 * C @ D ** 2 @ C\n",
    "    \n",
    "    #eigen decompose K\n",
    "    l, U = np.linalg.eigh(K)\n",
    "    \n",
    "    ##sort eigenvalues (and eigenvectors) into descending order\n",
    "    idx = l.argsort()[::-1]\n",
    "    l = l[idx]\n",
    "    U = U[:,idx]\n",
    "    \n",
    "    #sum of all eigen values\n",
    "    s = np.sum(l)\n",
    "    \n",
    "    #estimate the number of dimensions to keep\n",
    "    k = len(l)\n",
    "    var = 1\n",
    "    \n",
    "    while var > 0.95:\n",
    "        k -= 1\n",
    "        var = np.sum(l[:k]) / s\n",
    "    \n",
    "    k += 1\n",
    "   \n",
    "    print('reduced dimension of data',k)\n",
    "\n",
    "    #run mds\n",
    "    mds = man.MDS(n_components=k, max_iter=30000, dissimilarity=\"precomputed\", n_jobs=1)\n",
    "    emb = mds.fit(K)\n",
    "    \n",
    "    return emb.embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##GHSOM2 algorithm\n",
    "\n",
    "#H: graph\n",
    "#lam: lambda -- the number of epochs to train before assessing error\n",
    "#eta: learning rate\n",
    "#sigma: initial neighbourhood range\n",
    "#e_0: error of previous layer\n",
    "#e_sg: error must reduce by this much for growth to stop\n",
    "#e_en: error must be greater than this to expand neuron\n",
    "#layer: layer of som\n",
    "def ghsom2(G, lam, w, eta, sigma, e_0, e_sg, e_en, layer):\n",
    "    \n",
    "    print('num nodes',len(G))\n",
    "    print('connected',nx.is_connected(G))\n",
    "    \n",
    "    #embedding\n",
    "#     X = dsd_embedding(G)\n",
    "    X = floyd_embedding(G)\n",
    "    \n",
    "    #save embedding to graph\n",
    "    set_embedding(G, X, layer)\n",
    "    \n",
    "    print('embedded graph')\n",
    "    \n",
    "    #number of nodes in G\n",
    "    num_nodes = nx.number_of_nodes(G)\n",
    "    \n",
    "    ##number of training patterns to visit\n",
    "    N = min(num_nodes, 100)\n",
    "    \n",
    "    #create som for this neuron\n",
    "    network = som.initialise_network(X, 1, w)\n",
    "    \n",
    "    #initialise MQE\n",
    "    MQE = math.inf\n",
    "    \n",
    "    #train for l epochs\n",
    "    som.train_network(X, network, lam, eta, sigma, N)\n",
    "    \n",
    "    #classify nodes\n",
    "    som.assign_nodes(G, X, network, layer)\n",
    "    \n",
    "    while MQE >= e_sg * e_0:\n",
    "        \n",
    "        #save current error\n",
    "        prev_MQE = MQE\n",
    "    \n",
    "        #find neuron with greatest error\n",
    "        error_unit = som.identify_error_unit(network)\n",
    "        \n",
    "        if layer > 0:\n",
    "            \n",
    "            #expand network\n",
    "            som.expand_network2(G, network, error_unit, layer)\n",
    "                    \n",
    "            print('ghsom has expanded som',layer,'error',MQE)\n",
    "        \n",
    "        #train for l epochs\n",
    "        som.train_network(X, network, lam, eta, sigma, N)\n",
    "        \n",
    "        #delete superfluoous neurons\n",
    "        som.delete_neurons(network)\n",
    "\n",
    "        #classify nodes\n",
    "        som.assign_nodes(G, X, network, layer)\n",
    "\n",
    "        #calculate mean network error\n",
    "        MQE = som.update_errors(network)\n",
    "        \n",
    "        if np.linalg.norm(MQE - prev_MQE) < 1e-3:\n",
    "            \n",
    "            print('no improvement, stopping growth')\n",
    "            \n",
    "            break\n",
    "        \n",
    "    print('ghsom has terminated expansion',layer)\n",
    "    print('error',MQE)\n",
    "    \n",
    "    #recalculate error after neuron expansion\n",
    "    MQE = 0\n",
    "    \n",
    "    ##neuron expansion phase\n",
    "    #iterate thorugh all neruons and find neurons with error great enough to expand\n",
    "    for i in network.nodes():\n",
    "        \n",
    "        #unpack\n",
    "        ls = network.node[i]['ls']\n",
    "        e = network.node[i]['e']\n",
    "        \n",
    "        #check error\n",
    "        if e > e_en * e_0 and layer < len(labels) or e_0 == math.inf:\n",
    "#         if layer < len(labels) and len(ls) > 0:\n",
    "\n",
    "            if e_0 == math.inf:\n",
    "                e_0 = e\n",
    "        \n",
    "            #subgraph\n",
    "            H = G.subgraph(ls)\n",
    "            \n",
    "            #recursively run algorithm to create new network for subgraph of this neurons nodes\n",
    "            net, e = ghsom2(H, lam, w, eta, sigma, e_0, e_sg, e_en, layer + 1)\n",
    "            \n",
    "            #repack\n",
    "            network.node[i]['e'] = e\n",
    "            network.node[i]['n'] = net\n",
    "            \n",
    "            print('ghsom has built new layer',layer+1)\n",
    "            \n",
    "        #increase overall network error\n",
    "        MQE += e\n",
    "    \n",
    "    #mean MQE\n",
    "    MQE /= nx.number_of_nodes(network)\n",
    "    \n",
    "    #return network\n",
    "    return network, MQE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##LLE embed graph to euclidean space using graph laplacian\n",
    "#G: graph\n",
    "#k: number of nearest neighbours to look for\n",
    "def LLE(G, k):\n",
    "    \n",
    "    #number of nodes in the graph\n",
    "    n = nx.number_of_nodes(G)\n",
    "    \n",
    "    #adjacency graph matrix\n",
    "    A = nx.floyd_warshall(G)\n",
    "    \n",
    "    #initialise weight matrix\n",
    "    W = np.zeros((n, n))\n",
    "    \n",
    "    #iterate over all nodes to find neighbours\n",
    "    for i in range(n):\n",
    "        \n",
    "        #node of graph\n",
    "        node = G.nodes()[i]\n",
    "        \n",
    "        #distances from node\n",
    "        dist = np.array([v for k,v in A[node].items()])\n",
    "        \n",
    "        #get id of k nearest nodes\n",
    "        sorted_ids = np.argsort(dist)\n",
    "        \n",
    "        #k nearest neighbors\n",
    "        knn = sorted_ids[1:k+1]\n",
    "        \n",
    "        #sum\n",
    "        s = sum(dist[knn])\n",
    "        \n",
    "        #normalise weights for k nearest nodes\n",
    "        for j in knn:\n",
    "            W[i,j] = dist[j] / s\n",
    "    \n",
    "    #similarity matrix\n",
    "    K = (k - 1) * np.identity(n) - k / n * np.ones((n,n)) + W + np.transpose(W) - np.transpose(W) @ W\n",
    "    \n",
    "    #eigen decompose K\n",
    "    l, U = np.linalg.eig(W)\n",
    "    \n",
    "    #embedding into euclidean space\n",
    "    X = U\n",
    "    \n",
    "    #return\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##function for isomap embedding\n",
    "#G: graph\n",
    "#k: number of nearest neighbours\n",
    "def isomap_embedding(G, k):\n",
    "    \n",
    "    #number of nodes in the graph\n",
    "    n = nx.number_of_nodes(G)\n",
    "    \n",
    "    #distance matrix\n",
    "    fl = nx.floyd_warshall(G)\n",
    "    \n",
    "    ##use MDS to compute kernel and embed graph into euclidean space\n",
    "\n",
    "    #distance matrix\n",
    "    D = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        n1 = G.nodes()[i]\n",
    "        for j in range(n):\n",
    "            n2 = G.nodes()[j]\n",
    "            D[i,j] = fl[n1][n2]\n",
    "    \n",
    "    #centering matrix\n",
    "    C = np.identity(n) - np.ones((n, n)) / n\n",
    "    \n",
    "    #similarity matrix\n",
    "    K = -0.5 * C * D * C\n",
    "    \n",
    "    ##eigen decompose K (real values)\n",
    "    l, U = np.linalg.eigh(K)\n",
    "    \n",
    "    ##sort eigenvalues (and eigenvectors) into ascending order\n",
    "    idx = l.argsort()\n",
    "    l = l[idx]\n",
    "    U = U[:,idx]\n",
    "    \n",
    "    ##dimensions to keep\n",
    "    k = len(l[l < 1e-12])\n",
    "    \n",
    "    l = l[k:]\n",
    "    U = U[:,k:]\n",
    "    \n",
    "    #diagonal array of eigen values\n",
    "    lam = np.diag(l)\n",
    "    lam_inv_sqrt = np.diag(l ** 0.5)\n",
    "    \n",
    "    #position in euclidean space\n",
    "    X = U @ lam_inv_sqrt\n",
    "    \n",
    "    #return\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#perform principle component analysis\n",
    "# def pca(X, preserved_var):\n",
    "def my_pca(X, k):\n",
    "\n",
    "    #number of data points\n",
    "    n = len(X)\n",
    "    d = len(X[0])\n",
    "    \n",
    "    #centre\n",
    "    X = X - np.ones((n, n)) @ X / n\n",
    "    \n",
    "    #estimate co-variance matrix\n",
    "    C = 1 / n * np.transpose(X) @ X\n",
    "    \n",
    "    #eigen decompose C\n",
    "    l, U = np.linalg.eigh(C)\n",
    "    \n",
    "    ##sort eigenvalues (and eigenvectors) into descending order\n",
    "    idx = l.argsort()[::-1]\n",
    "    l = l[idx]\n",
    "    U = U[:,idx]\n",
    "    \n",
    "    #number of eigenvalues\n",
    "    num_eig = len(l)\n",
    "    \n",
    "    #normalise U\n",
    "    for j in range(num_eig):\n",
    "        U[:,j] = U[:,j] / np.linalg.norm(U[:,j])\n",
    "    \n",
    "#     #sum of eigenvalues\n",
    "#     sl = sum(l)\n",
    "    \n",
    "#     #determine number of dimensions to keep\n",
    "#     k = num_eig - 1\n",
    "#     var = 1\n",
    "    \n",
    "#     while var > preserved_var:\n",
    "        \n",
    "#         k -= 1\n",
    "#         var = sum(l[:k]) / sl\n",
    "        \n",
    "#     k += 1\n",
    "    \n",
    "#     print(\"pca dim lost\",d-k)\n",
    "    \n",
    "    #project X\n",
    "    Y = X @ U[:,:k]\n",
    "    \n",
    "    #return\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##laplacian eigenmap embedding\n",
    "def laplacian_eigenmap(G, k, sigma):\n",
    "    \n",
    "    #number of nodes in the graph\n",
    "    n = nx.number_of_nodes(G)\n",
    "    \n",
    "    #distance matrix\n",
    "    fl = nx.floyd_warshall(G)\n",
    "    \n",
    "    #intitialise distance matrix\n",
    "    d = np.zeros((n, n))\n",
    "    \n",
    "    #initialise adjacency matric\n",
    "    A = np.zeros((n, n))\n",
    "    \n",
    "    #find closest k neighbours\n",
    "    for i in range(n):\n",
    "        n1 = G.nodes()[i]\n",
    "        for j in range(n):\n",
    "            n2 = G.nodes()[j]\n",
    "            d[i,j] = fl[n1][n2]\n",
    "            \n",
    "        #get id of k nearest nodes\n",
    "        sorted_ids = np.argsort(d[i])\n",
    "        \n",
    "        #k nearest neighbors\n",
    "        knn = sorted_ids[:k]\n",
    "        \n",
    "        #gaussian similarity -- heat kernel\n",
    "        for j in knn:\n",
    "            A[i,j] = np.exp( -d[i,j] ** 2 / (2 * sigma ** 2) )   \n",
    "        \n",
    "    #degree matrix\n",
    "    D = np.sum(A, axis=1)\n",
    "    \n",
    "    #normalised graph laplacian\n",
    "    N = np.identity(n) - np.diag(D ** -0.5) @ A @ np.diag(D ** -0.5)\n",
    "    \n",
    "    #eigen decompose\n",
    "    l, U = np.linalg.eigh(N)\n",
    "    \n",
    "    ##sort eigenvalues (and eigenvectors) into ascending order\n",
    "    idx = l.argsort()\n",
    "    l = l[idx]\n",
    "    U = U[:,idx]\n",
    "    \n",
    "    ##dimensions to keep\n",
    "    k = len(l[l < 1e-12])\n",
    "    \n",
    "    print('embedding dim lost',k)\n",
    "    \n",
    "    #position matrix\n",
    "    X = np.diag(D ** -0.5) @ U\n",
    "    \n",
    "    #return \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "##function to read in dsd file and embed graph\n",
    "def embed_from_dsd_file(file, n):\n",
    "\n",
    "    #initialise D -- distance matrix\n",
    "    D = np.zeros((n + 1, n + 1))\n",
    "    \n",
    "    #initialise line counter i\n",
    "    i = 0\n",
    "    \n",
    "    #read dsd file\n",
    "    with open(file) as dsd_file:\n",
    "        \n",
    "        #read each line\n",
    "        for line in dsd_file:\n",
    "            \n",
    "            #append -1 to first line\n",
    "            l = np.array([])\n",
    "            \n",
    "            if i == 0:\n",
    "                l = np.append(l,-1)\n",
    "            \n",
    "            #save to D\n",
    "            D[i,:] = np.append(l,np.fromstring(line,sep='\\t'))\n",
    "            \n",
    "    \n",
    "    #remove frst row and column\n",
    "    D = D[1:,1:]\n",
    "    \n",
    "     #centreing matrix\n",
    "#     C = np.identity(n) - np.ones((n, n)) / n\n",
    "    \n",
    "#     #similarity matrix\n",
    "#     K = - 1/2 * C @ D @ C\n",
    "#     K = np.exp(- D ** 2 / (2 * nx.radius(G) ** 2))\n",
    "    #eigen decompose K\n",
    "#     l, U = np.linalg.eigh(K)\n",
    "    \n",
    "#     ##sort eigenvalues (and eigenvectors) into descending order\n",
    "#     idx = l.argsort()[::-1]\n",
    "#     l = l[idx]\n",
    "#     U = U[:,idx]\n",
    "    \n",
    "#     k = 3\n",
    "    \n",
    "# #     print('dsd embedding dim lost',k)\n",
    "    \n",
    "#     #position matrix\n",
    "# #     X = U[:,k:] @ np.diag(l[k:] ** 0.5)\n",
    "#     X = U[:,:k] @ np.diag(l[:k] ** 0.5)\n",
    "    \n",
    "# #     print(D[1,2])\n",
    "# #     print(np.linalg.norm(X[1] - X[2]))\n",
    "\n",
    "    mds = manifold.MDS(n_components=3, max_iter=300000, eps=1e-9, dissimilarity=\"precomputed\", n_jobs=-1)\n",
    "\n",
    "    emb = mds.fit(D)\n",
    "    \n",
    "    print('stress',emb.stress_)\n",
    "    \n",
    "    return emb.embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "##floyds embedding\n",
    "def floyd_embedding(G):\n",
    "    \n",
    "    n = len(G)\n",
    "    \n",
    "    fl = nx.floyd_warshall(G)\n",
    "    \n",
    "    #intitialise distance matrix\n",
    "    D = np.zeros((n, n))\n",
    "    \n",
    "    #find closest k neighbours\n",
    "    for i in range(n):\n",
    "        n1 = G.nodes()[i]\n",
    "        for j in range(n):\n",
    "            n2 = G.nodes()[j]\n",
    "            D[i,j] = fl[n1][n2]\n",
    "    \n",
    "    C = np.identity(n) - np.ones((n, n)) / n\n",
    "    \n",
    "    #similarity matrix\n",
    "#     K = - 1/2 * C @ D ** 2 @ C\n",
    "    K = np.exp(- D ** 2 / (2 * nx.radius(G) ** 2))\n",
    "    \n",
    "    #eigen decompose K\n",
    "    l, U = np.linalg.eigh(K)\n",
    "    \n",
    "    ##sort eigenvalues (and eigenvectors) into ascending order\n",
    "    idx = l.argsort()[::-1]\n",
    "    l = l[idx]\n",
    "    U = U[:,idx]\n",
    "    \n",
    "    s = sum(l)\n",
    "    \n",
    "    k = len(l)\n",
    "    var = 1\n",
    "    \n",
    "    while var > 0.95:\n",
    "        k -= 1\n",
    "        var = sum(l[:k]) / s\n",
    "    \n",
    "    k += 1\n",
    "    print('number of dimensions',k)\n",
    "    \n",
    "#     #position matrix\n",
    "#     X = U[:,:k] @ np.diag(l[:k] ** 0.5)\n",
    "    \n",
    "#     return X\n",
    "    \n",
    "#     mds = manifold.MDS(n_components=k, max_iter=300, dissimilarity=\"precomputed\", n_jobs=1)\n",
    "    mds = manifold.SpectralEmbedding(n_components=k, affinity=\"precomputed\")\n",
    "#     mds = manifold.TSNE(n_components=k, n_iter=10000000, metric=\"precomputed\")\n",
    "   \n",
    "    emb = mds.fit(K)\n",
    "    \n",
    "#     print('stress',emb.stress_)\n",
    "#     print(emb.affinity_matrix_)\n",
    "#     print(emb.kl_divergence_)\n",
    "    \n",
    "    return emb.embedding_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
